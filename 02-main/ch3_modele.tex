\chapter{Méthodologie}
\label{chap:proposition_modele}

Ce chapitre va explorer la création d'un modèle de machine learning de A à Z.

\localtableofcontents

\newpage

% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------

\section{Introduction}
La création d'un modèle de machine learning consiste en plusieurs phases distinctes. La Figure \ref{fig:ch3_resume_machine_learning_supervise} résume les principales étapes et servira de fil conducteur pour ce chapitre.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{03-tail/A1_fondamentaux_ML/A1_figures/A1_01_resume_machine_learning_supervise.png}
    \caption{Résumé de machine learning supervisé}
    \label{fig:ch3_resume_machine_learning_supervise}
\end{figure}

La première étape consiste à définir la tâche et à sélectionner l'algorithme approprié. La deuxième phase porte sur la création d'un dataset d'entraînement adapté aux besoins spécifiques du modèle. Enfin, une fois les performances du modèle validées, celui-ci peut être déployé en production. L'Annexe \ref{chap:fondamentaux_ml} présente l'ensemble des termes et concepts de machine learning utilisés dans ce chapitre.

Une section dédiée expose ensuite les différentes pistes explorées mais non retenues. Cette démarche, essentielle dans tout projet de recherche, mérite d'être valorisée car elle permet de comprendre le cheminement vers une solution viable. Le chapitre se conclut par une synthèse des points-clés développés.

La création d'un dataset dédié à la segmentation sémantique représente un défi considérable en termes de temps et de ressources. L'examen des datasets disponibles (Section \ref{sec:dataset_disponible}) révèle une carence majeure, seul le dataset RID propose des annotations pour l'identification des espaces libres sur toitures. Ce dataset présente toutefois des limitations importantes, avec des images concentrées sur un contexte architectural spécifique (rural allemand) et des performances dégradées lors des tests sur d'autres typologies bâties, comme le démontrent les essais menés en milieu urbain bruxellois.

% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------
\section{Tâche}
La tâche que ce modèle doit accomplir est d'identifier les espaces disponibles sur les toitures. Cette tâche est identique à celle de \acrshort{stdl} du chapitre \ref{subsec:stdl_analyse}, par contre l'approche utilisée va être différente.

\section{Algorithme}
Une fois la tâche définie, il faut déterminer une approche. \acrshort{stdl} a exploré 3 approches différentes:
\begin{itemize}
    \item La classification des pans de toit
    \item La segmentation des données \gls{lidar}
    \item La segmentation d'images
\end{itemize}

Leur segmentation d'images est réalisée avec Segment Anything Model (SAM). SAM effectue de la segmentation instance et divise l'image en polygones mais n'assigne pas de classe aux objets. Les résultats doivent être post-traités pour identifier les espaces disponibles. Un autre point délicat est le temps de traitement important (12 minutes pour 25 bâtiments).

La segmentation sémantique est une autre option explorée par \citeauthor{castello_quantification_2021} (Section \ref{subsec:castello_quantification_2021}). Ils l'ont utilisé pour exactement la même tâche avec un dataset limité au centre-ville de Genève. Les résultats obtenus avec un IoU supérieur à 0.60 sur leur dataset de test sont très encourageants.

La segmentation sémantique est le type d'algorithme retenu. Les autres pistes explorées mais qui n'ont pas été retenues sont détaillées dans la section \ref{sec:pistes_explorees}.

\section{Sélection des données}
La sélection des données va dépendre de l'algorithme utilisé. Dans ce cas, la segmentation sémantique d'image va principalement utiliser des orthophotos et des données vectorielles. Les données utilisées proviennent de \acrshort{sitg}:
\begin{itemize}
    \item Données vectorielles
    \begin{itemize}
        \item Bâtiments hors-sol ``CAD\_BATIMENT\_HORSOL'' \cite{sitg_batiments_nodate}
        \item Toits des bâtiments ``CAD\_BATIMENTS\_HORSOL\_TOIT'' \cite{sitg_toits_nodate}
        \item Superstructures des toits des bâtiments ``CAD\_BATIMENT\_HORSOL\_TOIT\_SP'' \cite{sitg_superstructures_nodate}
        \item Communes genevoises ``CAD\_COMMUNE'' \cite{sitg_communes_nodate}
    \end{itemize}
    \item Données raster (images)
    \begin{itemize}
        \item Orthophotos 2019 \cite{sitg_orthophotos_nodate}
    \end{itemize}
\end{itemize}

\subsection{Orthophotos}
Les orthophotos de 2019 (Figure \ref{fig:ch3_dataset_methodo_01_orthophoto_2019}) ont été sélectionnées car ce sont les seules true-orthophotos disponibles sur \acrshort{sitg} avec une résolution de 7cm par pixel. Selon un document de SITG \cite{etat_de_geneve_inventaire_2025}, ils ont réalisé plusieurs survols du canton en 2024 pour acquérir de nouvelles true-orthophotos avec une résolution de 3.6cm par pixel, ces orthophotos ne sont pas encore disponibles sur \acrshort{sitg}.

La sous-section \ref{subsec:annexe_ortophotos} parcours en détail les types d'orthophotos les plus utilisées dans la géomatique.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures/ch3/ch3_dataset_methodo_01_orthophoto_2019.png}
    \caption{Orthophotos 2019}
    \label{fig:ch3_dataset_methodo_01_orthophoto_2019}
\end{figure}

\subsubsection{Obtention des données}
Les orthophotos peuvent être commandées gratuitement via leur service pour données volumineuses \cite{sitg_commande_nodate}. Une autre option est de télécharger tuile à tuile sur leur site dédié (Figure \ref{fig:ch3_donnees_sitg_orthophotos_telechargement_web}).

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures//ch3/ch3_donnees_sitg_orthophotos_telechargement_web.png}
    \caption{Site dédié au téléchargement des orthophotos et données \gls{lidar} \cite{sitg_commande_nodate}}
    \label{fig:ch3_donnees_sitg_orthophotos_telechargement_web}
\end{figure}

Chacune des 436 tuiles couvre une superficie de \SI{1}{\square\kilo\meter}. L'ensemble de ces données représente environ 700 GB et est stocké au format GeoTIFF. Ce format présente l'avantage de conserver les informations géographiques associées à chaque image, notamment la géolocalisation des quatre coins et le système de coordonnées de référence (\acrshort{crs}) utilisé. Le Tableau \ref{tab:chiffre_cle_orthophoto_2019} présente un résumé de ces caractéristiques techniques.

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lr@{}}
    \toprule
    \textbf{Paramètre} & \textbf{Valeur} \\
    \midrule
    \multicolumn{2}{@{}l@{}}{\textit{Couverture}} \\
    Surface totale & \SI{436.00}{\square\kilo\meter} \\
    Nombre de tuiles & 436 \\
    Taille tuile & \SI{1000.00}{\meter} $\times$ \SI{1000.00}{\meter} \\
    \addlinespace
    \multicolumn{2}{@{}l@{}}{\textit{Stockage}} \\
    Taille totale & \SI{682.92}{\giga\byte} \\
    Taille par tuile & \SI{1603.91}{\mega\byte} \\
    \bottomrule
    \end{tabular}
    \caption{Chiffres-clés orthophotos 2019}
    \label{tab:chiffre_cle_orthophoto_2019}
\end{table}

\newpage
\subsection{Données vectorielles}
Les données vectorielles choisies sont régulièrement mises à jour, il n'y a pas de version par année comme pour les orthophotos. La sous-section \ref{subsec:annexe_donnees_vectorielles} permet d'avoir un aperçu de ce que sont les données vectorielles.
\subsubsection{Bâtiments hors-sol}
La couche vectorielle ``CAD\_BATIMENTS\_HORSOL'' \cite{sitg_batiments_nodate} recense tous les bâtiments du Canton de Genève qui sont bien ancrés au sol. Cette couche n'inclus pas les bâtiments qui sont sous-terrains. La Figure \ref{fig:ch3_dataset_methodo_02_batiment_horsol} permet d'observer ces polygones qui représentent les bâtiments en jaune.

Cette couche vectorielle est enrichie de données tabulaires associées à chacun des polygones. Les données utilisées sont l'``\gls{egid}'' et ``NOMEN\_CLASSE''. L'\gls{egid} est un identifiant unique pour tous les bâtiments en Suisse. ``NOMEN\_CLASSE'' identifie l'usage du bâtiment et va permettre de définir une classe \gls{sia}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures/ch3/ch3_dataset_methodo_02_batiment_horsol.png}
    \caption{Couche vectorielle bâtiments hors-sol}
    \label{fig:ch3_dataset_methodo_02_batiment_horsol}
\end{figure}


\newpage
\subsubsection{Toits des bâtiments}
La couche vectorielle ``CAD\_BATIMENTS\_HORSOL\_TOIT'' \cite{sitg_toits_nodate} regroupe toutes les toitures des bâtiments hors-sol du Canton de Genève (Figure \ref{fig:ch3_dataset_methodo_03_batiment_horsol_toiture}). Un \gls{egid} est associé à chacun des polygones des toitures.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures/ch3/ch3_dataset_methodo_03_batiment_horsol_toiture.png}
    \caption{Couche vectorielle toits des bâtiments}
    \label{fig:ch3_dataset_methodo_03_batiment_horsol_toiture}
\end{figure}

\newpage
\subsubsection{Superstructures des toits des bâtiments}
La couche vectorielle ``CAD\_BATIMENT\_HORSOL\_TOIT\_SP'' \cite{sitg_toits_nodate} inclus les superstructures de plus de 9 \si{\unit{\square\meter}} présentes sur les toitures des bâtiments hors-sol du Canton de Genève (Figure \ref{fig:ch3_dataset_methodo_04_batiment_horsol_toiture_sp}). Un \gls{egid} est associé à chacun des polygones des superstructures.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures/ch3/ch3_dataset_methodo_04_batiment_horsol_toiture_sp.png}
    \caption{Couche vectorielle superstructures des toits des bâtiments}
    \label{fig:ch3_dataset_methodo_04_batiment_horsol_toiture_sp}
\end{figure}

Cette couche est présentée ici car c'est ce qu'il y a de plus proche à un recueil systématique des obstacles sur les toitures. Elle ne sera pas utilisée. Son utilisation a été explorée dans la Section \ref{sec:pistes_explorees}.

\subsubsection{Obtention des données}
Les données vectorielles sont disponibles directement sur \acrshort{sitg} dans plusieurs formats (GDB, GML, KML ou SHP). Il est également possible d'y accéder via l'\acrshort{api} REST d'ArcGIS.

Pour faciliter le traitement, toutes les données sont converties au format GPKG \cite{noauthor_ogc_nodate}. Ce format, très utilisé en géomatique, a l'avantage d'être robuste et de regrouper toutes les données dans un seul fichier.
\newpage

\section{Labellisation}
Une fois que les données sont sélectionnées, l'étape suivante est la labellisation. Cette étape se divise en plusieurs parties:
\begin{itemize}
    \item Préparation des données
    \item Sélection des données pour le dataset
    \item Labellisation (annotations)
    \item Post-traitement des données annotées
\end{itemize}

\subsection{Préparation des données}
Les données sélectionnées nécessitent d'être analysées, transformées et validées avant de pouvoir les annoter.

\subsubsection{Données vectorielles}
La Figure \ref{fig:ch3_preparation_donnees_01_etl} résume les principales étapes pour les données vectorielles.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{02-main/figures/ch3/ch3_preparation_donnees_01_etl.png}
    \caption{Principales étapes de la préparation des données vectorielles}
    \label{fig:ch3_preparation_donnees_01_etl}
\end{figure}

\paragraph{Nettoyage des données}
Les deux principales librairies Python utilisées pour la manipulation des données vectorielles sont Pandas \cite{mckinney_pandas_nodate} et GeoPandas \cite{noauthor_geopandas_nodate}. Pandas est la librairie la plus populaire pour la manipulation des données tabulaires. GeoPandas étend ces fonctionnalités aux données géospatiales en intégrant la gestion des géométries et l'ensemble des opérations spatiales telles que les jointures spatiales.

Le but de cette étape est de vérifier la qualité des données de base. Les géométries (polygones) constituent une donnée essentielle en géomatique. Elles doivent être valides (polygones fermés) et utiliser le bon système de coordonnées de référence (\acrshort{crs}).

Le type des différentes colonnes est également important. Le schéma des données définit les types attendus pour chaque colonne de chaque couche (voir Tableau \ref{tab:exemple_types_couche_toitures}).

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lr@{}}
    \toprule
    \textbf{Colonne} & \textbf{Type} \\
    \midrule
    objectid & int64 \\
    egid & float64 \\
    altitude\_min & float64 \\
    altitude\_max & float64 \\
    date\_leve & datetime64[ms] \\
    SHAPE\_\_Length & float64 \\
    SHAPE\_\_Area & float64 \\
    globalid & object \\
    geometry & geometry \\
    \bottomrule
    \end{tabular}
    \caption{Exemple de types pour la couche des toitures}
    \label{tab:exemple_types_couche_toitures}
\end{table}

Cette étape de vérification est essentielle pour les opérations de jointure entre les différentes couches de données. Les colonnes servant de clés de jointure doivent avoir des types compatibles. Par exemple, une colonne de type int64 (nombres entiers) ne peut pas être directement jointe avec une colonne de type float64 (nombres à virgule flottante) sans conversion préalable. Toutes les colonnes doivent être vérifiées et converties si nécessaire au bon type.

\newpage
La visualisation des données permet de détecter certains problèmes difficilement visibles dans les données tabulaires. Par exemple, la couche des communes téléchargée via l'\acrshort{api} REST d'ArcGIS (Figure \ref{fig:ch3_preparation_donnees_02_bug_celigny}) présentait des géométries invalides (commune de Céligny), c'est-à-dire que les polygones n'étaient pas fermés et étaient donc systématiquement supprimés.

Pour résoudre ce problème et par cohérence, toutes les données ont été téléchargées à nouveau directement depuis \acrshort{sitg}. Ces nouvelles données ne présentaient pas ce problème, ce qui suggère que l'erreur vient du processus de téléchargement via QGIS.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures//ch3/ch3_preparation_donnees_02_bug_celigny.png}
    \caption{Problème avec la commune de Céligny}
    \label{fig:ch3_preparation_donnees_02_bug_celigny}
\end{figure}

\newpage
\paragraph{Filtrer polygones hors canton}
Certains polygones se trouvent en dehors du canton de Genève. Le filtre est assez simple, tout ce qui n'est pas à l'intérieur d'une commune genevoise est considéré comme hors canton.

La Figure \ref{fig:ch3_preparation_donnees_03_hors_canton} illustre les toitures situées hors canton. Au total, 1436 polygones ont été supprimés, principalement des bâtiments du CERN \cite{cern_home_nodate}.

\begin{figure}[H]
    \makebox[\textwidth][c]{\includegraphics[width=1.15\textwidth]{02-main//figures//ch3/ch3_preparation_donnees_03_hors_canton.png}}
    \caption{Visualisation des toitures hors canton de Genève}
    \label{fig:ch3_preparation_donnees_03_hors_canton}
\end{figure}

\newpage
\paragraph{Filtrer les \gls{egid}}
Le filtre appliqué précédemment a éliminé une grande partie des \gls{egid} invalides, mais il est important de bien vérifier car l'\gls{egid} est la clé de jointure entre toutes les couches.

L'\gls{egid} minimum de la couche des bâtiments hors-sol est utilisé comme filtre (Code \ref{code:filtre_egid}) pour identifier les \gls{egid} invalides. Cette vérification détecte un total de 24 \gls{egid} invalides dans la couche des toitures.

\vspace{0.35cm}
\begin{pythoncode}
# EGID bizarre
egid_bizarre = gdf_cad_batiment_horsol["egid"].min()

print("EGID min de gdf_cad_batiment_horsol:", egid_bizarre)
print("Nombre de toitures avec un EGID en dessous (invalide):")

print(f"\t{gdf_toiture[gdf_toiture['egid'] < egid_bizarre].shape[0]} \
dans gdf_toiture_1_filtre_canton")

print(f"\t{gdf_toiture_sp[gdf_toiture_sp['egid'] < egid_bizarre].shape[0]} \
dans gdf_toiture_sp_1_filtre_canton")
\end{pythoncode}

\begin{textcode}
EGID min de gdf_cad_batiment_horsol: 295074
Nombre de toitures avec un EGID en dessous (invalide):
    22 dans gdf_toiture_1_filtre_canton
    2 dans gdf_toiture_sp_1_filtre_canton
    0 dans gdf_cad_batiment_horsol
\end{textcode}
\captionof{code}{Filtre \gls{egid}}
\label{code:filtre_egid}

\paragraph{Classification \gls{sia}}
En Suisse, chaque bâtiment peut être classé selon son utilisation en 12 catégories définies par la norme SIA 380/1 (Tableau \ref{tab:categories_batiments_sia_380_1}). Cette classification est importante pour l'analyse des caractéristiques des toitures, une toiture de logement collectif ne ressemblera pas à celle d'une usine ou d'une piscine.

\begin{table}[H]
    \centering
    \begin{tabular}{@{}clp{0.65\textwidth}@{}}
    \toprule
    \textbf{N°} & \textbf{Catégories de bâtiment} & \textbf{Affectations (exemples)} \\
    \midrule
    I & Habitat collectif & Immeubles locatifs et en propriété par appartement, résidences et logements pour personnes âgées, hôtels, immeubles et résidences de vacances, homes pour enfants ou adolescents, centres d'hébergement diurne, homes pour handicapés, centres d'accueil pour toxicomanes, casernes, établissements pénitentiaires \\
    II & Habitat individuel & Villas individuelles ou jumelées, maisons de vacances, villas en chaînettes \\
    III & Administration & Bâtiments administratifs privés et publics, locaux avec guichets, cabinets médicaux, bibliothèques, musées, centres culturels, centres informatiques, centres de télécommunication, studios de radio/télévision \\
    IV & Écoles & Bâtiments scolaires de tous niveaux, jardins d'enfants et crèches, locaux d'enseignement, centres de formation, palais des congrès, laboratoires, instituts de recherche, locaux communautaires, centres de loisirs \\
    V & Commerce & Locaux commerciaux de tous genres, y compris centres commerciaux, halles pour foires commerciales \\
    VI & Restauration & Restaurants (y compris cuisines), cafétérias, cantines, dancings, discothèques \\
    VII & Lieux de rassemblement & Théâtres, salles de concerts, salles de cinéma, églises, salles funéraires, salles des fêtes, halles sportives avec tribunes \\
    VIII & Hôpitaux & Hôpitaux, cliniques psychiatriques, homes médicalisés, homes pour personnes âgées, centres de réhabilitation, locaux de soins \\
    IX & Industrie & Fabriques, usines, centres artisanaux, ateliers, centres d'entretien, gares, caserne de pompiers \\
    X & Dépôts & Entrepôts, centre de distribution \\
    XI & Installations sportives & Halles de gymnastique et de sport, salles de gymnastique, halles de tennis, bowlings, centres de fitness, vestiaires (pour installations sportives) \\
    XII & Piscines couvertes & Piscines couvertes, bassins de natation, saunas, bains thermaux \\
    \bottomrule
    \end{tabular}
    \caption{Catégories de bâtiments \gls{sia} selon la norme \gls{sia} 380/1:2016 \cite{sia_sia-shop_nodate}}
    \label{tab:categories_batiments_sia_380_1}
\end{table}

\newpage
Cette information n'est pas incluse directement dans la couche des bâtiments hors-sol, par contre la destination est renseignée pour chaque \gls{egid}. Le Code \ref{code:assigner_categorie_sia} montre un exemple de conversion pour la première catégorie \gls{sia}.

\vspace{0.35cm}
\begin{pythoncode}
def assign_sia_category(destination):
    """
    Attribue une catégorie SIA 380/1:2016 en fonction de la destination du bâtiment.
    """
    # Conversion en minuscules pour la comparaison
    dest = str(destination).lower()

    # ===== CATÉGORIE I - HABITAT COLLECTIF =====
    habitat_collectif = [
        "hab plusieurs logements",
        "résidence meublée",
        "foyer",
        "hôtel",
        "autre héberg. collectif",
        "etab. pénitenciaire",
        "internat",
        "hab. - rez activités",
        "habitation - activités",
    ]
    if any(term in dest for term in habitat_collectif):
        return "I habitat collectif"

gdf_cad_batiment_horsol['sia_cat'] = gdf_cad_batiment_horsol['destination'].apply(assign_sia_category)
\end{pythoncode}
\captionof{code}{Exemple de conversion entre la destination et la première catégorie \gls{sia}}
\label{code:assigner_categorie_sia}

La première vérification consiste à s'assurer que tous les \gls{egid} possèdent une catégorie \gls{sia} et à analyser la distribution de ces catégories. Le Code \ref{code:categorie_sia_distribution_verification} inclut une instruction ``assert'' qui interrompt le script si tous les \gls{egid} ne disposent pas d'une catégorie assignée.

\vspace{0.35cm}
\begin{pythoncode}
print(gdf_cad_batiment_horsol["sia_cat"].value_counts())
print(f"Nombre de valeurs manquantes dans sia_cat: {gdf_cad_batiment_horsol["sia_cat"].isna().sum()}")
assert gdf_cad_batiment_horsol["sia_cat"].isna().sum() == 0
\end{pythoncode}
\vspace{0.35cm}
\begin{textcode}
sia_cat
II habitat individuel         29420
IX industrie                  16947
X dépôts                      16575
I habitat collectif           15337
III administration             1836
IV écoles                       746
VII lieux de rassemblement      520
V commerce                      415
XI installations sportives      257
VIII hôpitaux                   233
VI restauration                 205
XII piscines couvertes           11
Name: count, dtype: int64
Nombre de valeurs manquantes dans sia_cat: 0
\end{textcode}
\captionof{code}{Distribution des catégories \gls{sia} et vérification des données.}
\label{code:categorie_sia_distribution_verification}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures//ch3/ch3_preparation_donnees_categorie_sia_01_barplot.png}
    \caption{Distribution des catégories \gls{sia} pour la couche des bâtiments hors-sol}
    \label{fig:ch3_preparation_donnees_categorie_sia_01_barplot}
\end{figure}

La Figure \ref{fig:ch3_preparation_donnees_categorie_sia_01_barplot} illustre la distribution des bâtiments par catégorie \gls{sia}. Cette distribution est assez déséquilibrée. Le canton de Genève est très urbain et densément peuplé, ce qui explique la prédominance des logements collectifs et individuels.

Certaines catégories comme les piscines couvertes sont peu représentées. Cette rareté peut s'expliquer par une incertitude sur la qualité des données renseignées dans la destination du bâtiment. Par exemple, un complexe sportif avec une piscine couverte pourrait avoir seulement la destination ``complexe sportif''.

Les catégories \gls{sia} (Tableau \ref{tab:categories_batiments_sia_380_1}) indiquent des exemples de bâtiments pour chacune des catégories mais il n'y a pas de liste complète. Certains cas sont entre deux catégories, un centre de massage peut être classé comme commerce ou comme hôpital (locaux de soins).

\paragraph{Données finales}
Les données finales (Tableau \ref{tab:gdf_toiture_ajout_cat_sia_parquet_head}) comprennent plusieurs colonnes essentielles; L'``EGID'' permet d'associer chaque toiture à un bâtiment, la colonne ``geometry'' contient la géométrie du polygone dans le système de coordonnées suisse, et ``sia\_cat'' indique la catégorie \gls{sia} du bâtiment. 

Les colonnes d'identification ``objectid'' et ``globalid'' permettent respectivement d'identifier chaque polygone de manière unique au sein de la couche et à travers l'ensemble des couches de \acrshort{sitg}.

\begin{table}[H]
\renewcommand{\arraystretch}{2}
\begin{tabular}{@{}rlp{3cm}p{3cm}l@{}}
\toprule
objectid & egid & globalid & geometry & sia\_cat \\
\midrule
204857 & 295010023 & \parbox{3cm}{96076844-3ED9-464...} & \parbox{3cm}{MULTIPOLYGON (((2...} & II habitat individuel \\
204873 & 295010485 & \parbox{3cm}{987C8B52-793B-4BB...} & \parbox{3cm}{MULTIPOLYGON (((2...} & II habitat individuel \\
7630 & 295510865 & \parbox{3cm}{E3C6375D-ECCC-4A0...} & \parbox{3cm}{MULTIPOLYGON (((2...} & X dépôts \\
\bottomrule
\end{tabular}
\caption{Principales colonnes de gdf\_toiture\_ajout\_cat\_sia.parquet}
\label{tab:gdf_toiture_ajout_cat_sia_parquet_head}
\end{table}

Le format choisi pour le stockage du fichier est le geoparquet \cite{noauthor_geoparquet_nodate}. Ce format étend le standard open source parquet \cite{noauthor_parquet_nodate} en y intégrant toutes les spécificités nécessaires à la gestion des données géospatiales. Il combine ainsi les avantages de performance du format parquet (compression efficace, lecture rapide) avec la gestion native des géométries.

\newpage
\subsubsection{Orthophotos}
\paragraph{Dimensions des orthophotos et contraintes}
Les 416 orthophotos sont des fichiers au format GeoTIFF de dimensions 20000×20000 pixels. Cependant, la plupart des réseaux de neurones convolutifs sont entraînés sur des images de tailles comprises entre 224×224 et 1024×1024 pixels, correspondant aux standards des architectures classiques. Le découpage de ces orthophotos est nécessaire pour adapter les données aux contraintes des modèles.

\paragraph{Processus de découpage}
La Figure \ref{fig:ch3_preparation_donnees_orthophotos_01_etl} décrit les étapes de ce processus de découpage. Chaque tuile générée mesure 1280×1280 pixels (64×64 mètres) avec un recouvrement de 256 pixels (12,80 mètres) avec les tuiles adjacentes. Ce recouvrement garantit qu'aucun bâtiment ne soit coupé aux bordures des tuiles.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_preparation_donnees_orthophotos_01_etl.png}
    \caption{Découpe des orthophotos en tuiles 1280x1280 pixels avec recouvrement}
    \label{fig:ch3_preparation_donnees_orthophotos_01_etl}
\end{figure}

\newpage
\paragraph{Zone urbaine}
La Figure \ref{fig:ch3_preparation_donnees_orthophotos_02_exemple_decoupe_orthophoto1} illustre la démarche adoptée. Pour chaque orthophoto, l'algorithme charge d'abord l'image et identifie toutes les toitures situées dans son périmètre. 

Un quadrillage de tuiles de 1280×1280 pixels avec un recouvrement de 256 pixels est ensuite créé. Le processus parcourt le quadrillage de manière itérative, du coin supérieur gauche vers le coin inférieur droit. Seules les tuiles contenant au moins une toiture sont conservées et sauvegardées; les tuiles vides sont rejetées. Dans ce cas, 388 tuiles ont été retenues sur les 400 tuiles possibles par orthophoto.

Dans les zones urbaines caractérisées par une forte densité de bâtiments, chaque orthophoto génère un nombre élevé de tuiles. Cette concentration de données est particulièrement intéressante pour l'entraînement du modèle, car elle offre une grande variété d'exemples architecturaux dans un espace géographique restreint.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_preparation_donnees_orthophotos_02_exemple_decoupe_orthophoto1.png}
    \caption{Exemple de découpage d'une orthophoto en tuiles pour une zone urbaine}
    \label{fig:ch3_preparation_donnees_orthophotos_02_exemple_decoupe_orthophoto1}
\end{figure}

\newpage
La Figure \ref{fig:ch3_preparation_donnees_orthophotos_03_exemple_decoupe_orthophoto2} présente le calepinage des tuiles conservées. Cette représentation illustre plus clairement le principe de recouvrement que la Figure \ref{fig:ch3_preparation_donnees_orthophotos_02_exemple_decoupe_orthophoto1}, une tuile peut être entièrement entourée par d'autres tuiles qui se chevauchent avec elle.

Il convient de noter que toutes les tuiles générées ne présentent pas des dimensions de 1280×1280 pixels. Les tuiles situées en bordure droite de la Figure \ref{fig:ch3_preparation_donnees_orthophotos_03_exemple_decoupe_orthophoto2} sont plus étroites (tuile 18), de même que celles situées en partie basse (tuile 371).

Ces cas particuliers seront traités après la finalisation de l'annotation. La priorité a été donnée à l'obtention de distributions de tuiles identiques pour l'ensemble des orthophotos, afin d'avoir une cohérence dans le processus de découpage et post-traitement.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_preparation_donnees_orthophotos_03_exemple_decoupe_orthophoto2.png}
    \caption{Calepinage des tuiles découpées pour la zone urbaine}
    \label{fig:ch3_preparation_donnees_orthophotos_03_exemple_decoupe_orthophoto2}
\end{figure}

\newpage
La tuile 258 (Figure \ref{fig:ch3_preparation_donnees_orthophotos_04a_exemple_decoupe_orthophoto3}), située à proximité de HEPIA, illustre bien cette complexité. Chaque tuile peut avoir jusqu'à 8 zones de recouvrement avec ses voisines (Figure \ref{fig:ch3_preparation_donnees_orthophotos_04_exemple_decoupe_orthophoto3}) au nord (238), nord-est (239), est (259), sud-est (279), sud (278), sud-ouest (277), ouest (257) et nord-ouest (237). Seule la zone centrale de 1024×1024 pixels n'a aucun recouvrement et constitue la partie unique de chaque tuile.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.40\linewidth]{02-main/figures/ch3/ch3_preparation_donnees_orthophotos_04a_exemple_decoupe_orthophoto3.png}
    \caption{Tuile 258}
    \label{fig:ch3_preparation_donnees_orthophotos_04a_exemple_decoupe_orthophoto3}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.90\linewidth]{02-main/figures/ch3/ch3_preparation_donnees_orthophotos_04_exemple_decoupe_orthophoto3.png}
    \caption{Recouvrement pour la tuile 258}
    \label{fig:ch3_preparation_donnees_orthophotos_04_exemple_decoupe_orthophoto3}
\end{figure}


\newpage
\paragraph{Zone rurale}
La Figure \ref{fig:ch3_preparation_donnees_orthophotos_05_exemple_decoupe_orthophoto4} illustre le découpage dans une zone plus rurale. Ces zones présentent des caractéristiques architecturales très différentes des zones urbaines, avec notamment des villas individuelles, des bâtiments agricoles et des constructions plus dispersées sur le territoire. Cette diversité typologique est nécessaire pour constituer un dataset riche et varié.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_preparation_donnees_orthophotos_05_exemple_decoupe_orthophoto4.png}
    \caption{Exemple de découpage d'une orthophoto en tuiles pour une zone rurale}
    \label{fig:ch3_preparation_donnees_orthophotos_05_exemple_decoupe_orthophoto4}
\end{figure}

Comme observé précédemment, cette figure révèle également quelques bugs dans le script de traitement des tuiles, avec des tuiles manquantes par endroits (nord 41-42). Cependant, l'analyse à l'échelle du canton (Figure \ref{fig:ch3_preparation_donnees_orthophotos_07_exemple_decoupe_orthophoto6}) confirme que ces erreurs ponctuelles ne compromettent pas la qualité globale du découpage.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_preparation_donnees_orthophotos_07_exemple_decoupe_orthophoto6.png}
    \caption{Tuiles découpées pour toutes les orthophotos}
    \label{fig:ch3_preparation_donnees_orthophotos_07_exemple_decoupe_orthophoto6}
\end{figure}

\newpage
\paragraph{Implémentation}
Le Code \ref{code:pseudo_code_decoupe_orthophotos_tuiles_1280_1280} utilise du pseudo-code pour expliquer les étapes de découpage. Les principales librairies employées sont rasterio \cite{noauthor_rasterio_nodate} et shapely \cite{noauthor_shapely_nodate}. Rasterio permet la manipulation des données raster (orthophotos), tandis que shapely offre une boîte à outils complète pour le traitement des géométries et données géospatiales.
\vspace{0.35cm}
\begin{textcode}
DÉBUT process_geotiff_with_buildings(geotiff, gdf_batiments, output)
    
    // Chargement des données
    CHARGER les géométries des bâtiments depuis le gdf_batiments
    OUVRIR le fichier GeoTIFF source
    
    // Préparation spatiale
    REPROJETER les bâtiments dans le même système de coordonnées que le GeoTIFF
    CRÉER un index spatial pour optimiser les requêtes géométriques
    FILTRER les bâtiments qui intersectent avec le GeoTIFF sélectionné
    
    // Découpage en tuiles
    CALCULER le nombre de tuiles nécessaires (largeur × hauteur / taille_tuile)
    
    POUR chaque position de tuile (i, j) FAIRE
        DÉFINIR la fenêtre de la tuile courante (1024x1024 pixels)
        CALCULER l'emprise géographique de la tuile
        CRÉER la zone de recouvrement autour de la tuile (1280x1280 pixels)
        
        // Détection des bâtiments
        RECHERCHER les bâtiments qui intersectent la zone tamponnée
        
        SI aucun bâtiment trouvé ALORS
            PASSER à la tuile suivante
        SINON
            EXTRAIRE les données raster de la zone tamponnée
            SAUVEGARDER la tuile au format GeoTIFF
            ENREGISTRER les métadonnées (géométries, identifiants, coordonnées)
        FIN SI
    FIN POUR
    
    SAUVEGARDER toutes les métadonnées dans un fichier Parquet
    RETOURNER le chemin du fichier de métadonnées
    
FIN process_geotiff_with_buildings
\end{textcode}
\captionof{code}{Pseudo-code pour la découpe des orthophotos 20000x20000 pixels en tuiles de 1280x1280 pixels}
\label{code:pseudo_code_decoupe_orthophotos_tuiles_1280_1280}

La gestion de la mémoire peut devenir critique, chaque orthophoto occupant 1,4 Go. Il est possible de paralléliser la tâche, mais cela nécessite une machine disposant de suffisamment de mémoire RAM. 

Lors de l'exécution, le principal goulot d'étranglement est l'accès aux images plutôt que le traitement. Si plusieurs images sont ouvertes simultanément, le système de stockage n'est pas toujours suffisamment rapide et constitue le facteur limitant. Avec une configuration de 4 cœurs et 64 Go de RAM, le processus complet a pris environ 2 heures.

\paragraph{Métadonnées}
Le fichier parquet résultant (Tableau \ref{tab:ch3_preparation_donnees_orthophotos_parquet_resultat}) va être essentiel pour la sélection des données du dataset, il inclut tous les éléments nécessaires pour clairement identifier les toitures ainsi que les tuiles associées.
\begin{table}[H]
    \centering
    \begin{tabular}{@{}llp{0.55\textwidth}@{}}
    \toprule
    \textbf{Nom de la colonne} & \textbf{Type} & \textbf{Description} \\
    \midrule
    geotiff\_path & object & Chemin vers le fichier GeoTIFF source \\
    tile\_path & object & Chemin vers le fichier de tuile généré \\
    tile\_id & object & Identifiant unique de la tuile \\
    tile\_row & int64 & Numéro de ligne de la tuile dans la grille \\
    tile\_col & int64 & Numéro de colonne de la tuile dans la grille \\
    tile\_bounds & object & Limites géographiques de la tuile \\
    buffered\_bounds & object & Limites géographiques avec zone tampon \\
    tile\_size & int64 & Taille de la tuile en pixels \\
    buffer\_size & int64 & Taille de la zone tampon en pixels \\
    tile\_pixel\_size & object & Résolution spatiale du pixel de la tuile \\
    objectid & int64 & Identifiant dans la couche des toitures \\
    egid & int64 & \gls{egid} \\
    altitude\_min & float64 & Altitude minimale de la toiture \\
    altitude\_max & float64 & Altitude maximale de la toiture\\
    date\_leve & datetime64[ns] & Date de levé de la toiture \\
    SHAPE\_\_Length & float64 & Périmètre de la géométrie en mètres \\
    SHAPE\_\_Area & float64 & Surface de la géométrie en mètres carrés \\
    globalid & object & Identifiant global unique dans \acrshort{sitg} \\
    geometry & geometry & Géométrie du polygone de toiture géoréférencé \\
    \bottomrule
    \end{tabular}
    \caption{Description des colonnes du fichier parquet résultat}
    \label{tab:ch3_preparation_donnees_orthophotos_parquet_resultat}
\end{table}

\paragraph{Résultats}
Au final, le processus génère 38294 tuiles pour 77993 \gls{egid} uniques à l'échelle du canton. Étant donné qu'un bâtiment peut fréquemment se retrouver sur plusieurs tuiles en raison du recouvrement, cela représente 672253 associations toiture-tuile. Les orthophotos situées près de la zone aéroportuaire, qui incluent une partie du territoire français, ne sont pas incluses dans le périmètre d'étude.

Ces plus de 38000 tuiles constituent une base suffisante pour sélectionner les images nécessaires à la constitution d'un dataset représentatif et équilibré.

\newpage

\subsubsection{Sélection des données pour le dataset}
La sélection des données nécessite une analyse des tuiles afin d'identifier les caractéristiques des toitures présentes. Les critères retenus pour cette sélection sont la classe \gls{sia} et la surface des toitures.

\paragraph{Classe \gls{sia}}
Ce critère repose sur l'hypothèse que les classes \gls{sia} regroupent des bâtiments aux caractéristiques architecturales similaires. Par exemple, les toitures industrielles sont généralement plates avec une construction légère, tandis que de nombreuses écoles ont été construites par les mêmes architectes avec des plans similaires.

Pour analyser la distribution des tuiles par classe \gls{sia}, chaque tuile peut contenir plusieurs classes représentées. La classe dite dominante correspond à celle qui est majoritaire dans une tuile donnée.

La Figure \ref{fig:ch3_selection_donnees_01_distribution_sia} illustre la distribution des classes \gls{sia} dominantes par tuile. Cette distribution présente une forte similarité avec celle des classes \gls{sia} pour les bâtiments hors-sol (Figure \ref{fig:ch3_preparation_donnees_categorie_sia_01_barplot}). Cette cohérence est nécessaire pour préserver la représentativité de l'échantillon lors de la sélection du dataset.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_selection_donnees_01_distribution_sia.png}
    \caption{Distribution des classes \gls{sia} dominantes par tuile}
    \label{fig:ch3_selection_donnees_01_distribution_sia}
\end{figure}

\newpage
\paragraph{Surface des toitures}
Le deuxième critère retenu est la surface des toitures. Pour chaque tuile, la somme des surfaces de toiture est calculée, permettant ainsi de classifier les tuiles selon leur densité de couverture bâtie. Cette métrique distingue les tuiles avec une forte concentration de toitures, typiques des zones urbaines denses, de celles présentant une couverture plus éparse, caractéristiques des zones rurales ou de périphérie.

La Figure \ref{fig:ch3_selection_donnees_02_taille_bin} représente cette distribution par intervalles de surface. Les intervalles ont été choisis de manière empirique dans le but de refléter les ordres de grandeur caractéristiques des différents types de bâtiments. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_selection_donnees_02_taille_bin.png}
    \caption{Distribution des surfaces de toitures par intervalles}
    \label{fig:ch3_selection_donnees_02_taille_bin}
\end{figure}

Chaque intervalle correspond à une typologie architecturale spécifique. Le plus petit intervalle (0-200 \si{\unit{\square\meter}}) inclut les petits bâtiments individuels et les villas. Le deuxième (200-500 \si{\unit{\square\meter}}) regroupe les petits bâtiments de logement collectif. Les intervalles suivants (500-1000 \si{\unit{\square\meter}}, 1000-2000 \si{\unit{\square\meter}}, 2000-5000 \si{\unit{\square\meter}}) correspondent respectivement aux logements collectifs de taille moyenne, aux grands ensembles résidentiels et aux bâtiments industriels ou commerciaux. Enfin, l'intervalle supérieur (plus de 5000 \si{\unit{\square\meter}}) regroupe les grandes infrastructures industrielles, commerciales ou publiques.

\newpage
\paragraph{Échantillonnage stratifié}
L'échantillonnage des tuiles s'effectue selon une approche stratifiée pour garantir une représentation équilibrée de chaque catégorie. Cette méthode repose sur deux critères de stratification, la classe dominante (\texttt{dominant\_class}) et la catégorie de surface (\texttt{area\_bin}). 

La fonction \texttt{sample\_tiles} (Code \ref{code:echantillonnage_tuiles}) implémente cette logique d'échantillonnage avec un paramètre \texttt{random\_state=42} qui permet la reproductibilité des résultats en fixant la graine du générateur de nombres aléatoires.

\vspace{0.35cm}
\begin{pythoncode}
def sample_tiles(group, n_samples):
    """
    Échantillonne aléatoirement n_samples éléments d'un groupe.
    Si le groupe contient moins d'éléments que demandé, retourne tous les éléments.
    """
    if len(group) > n_samples:
        return group.sample(n=n_samples, random_state=42)
    else:
        return group
\end{pythoncode}
\captionof{code}{Fonction d'échantillonnage stratifié par groupe}
\label{code:echantillonnage_tuiles}

Cette stratégie utilise la méthode \texttt{groupby} pour créer des sous-groupes homogènes selon chaque combinaison des critères de stratification. La constante \texttt{SAMPLES\_PER\_CAT} (fixée à 8) définit le nombre maximum d'échantillons à extraire par catégorie, permettant ainsi de définir précisément la taille du dataset souhaité.

\vspace{0.35cm}
\begin{pythoncode}
# Application de l'échantillonnage stratifié
sampled_df = tile_groups.groupby(['dominant_class', 'area_bin']).apply(
    sample_tiles, n_samples=SAMPLES_PER_CAT
).reset_index(drop=True)
\end{pythoncode}
\captionof{code}{Application de l'échantillonnage stratifié}
\label{code:application_echantillonnage}

L'objectif est d'obtenir un sous-groupe homogène de 8 individus pour chaque combinaison classe \gls{sia} dominante / intervalle de surface. Avec 6 intervalles de surface définis par classe \gls{sia}, cela représente 48 individus par classe. Pour l'ensemble des 12 classes \gls{sia} considérées dans l'étude, le dataset cible comprend au total 576 individus stratifiés.

\paragraph{Résultats}
L'échantillon obtenu (Figure \ref{fig:ch3_selection_donnees_03_selection_stacked}) contient 539 échantillons au lieu de l'objectif fixé à 576. Cette différence s'explique par la rareté de certaines combinaisons classe \gls{sia} / intervalle de surface, particulièrement pour la restauration et les piscines couvertes.

Pour la restauration, seuls 2 \gls{egid} ont une surface supérieure à 5000 \si{\unit{\square\meter}} à l'échelle du canton. Ces deux individus sont donc automatiquement inclus dans la sélection pour cette combinaison spécifique, sans pouvoir atteindre l'objectif de 8 individus.

Les piscines couvertes constituent également un cas particulier avec seulement 11 \gls{egid} sur l'ensemble du canton (Figure \ref{fig:ch3_preparation_donnees_categorie_sia_01_barplot}). Ces bâtiments, généralement de taille conséquente avec des surfaces supérieures à 2000 \si{\unit{\square\meter}} dans la plupart des cas, ne permettent pas d'atteindre la représentation souhaitée dans tous les intervalles de surface.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_selection_donnees_03_selection_stacked.png}
    \caption{Sélection de l'échantillon pour le dataset}
    \label{fig:ch3_selection_donnees_03_selection_stacked}
\end{figure}

L'échantillonnage stratifié permet de sélectionner de manière aléatoire les individus qui formeront les différents sous-groupes selon chaque combinaison classe \gls{sia} / intervalle de surface. La Figure \ref{fig:ch3_selection_donnees_04_selection_map_sia} confirme que l'échantillon inclut des tuiles réparties sur l'ensemble du canton, garantissant une bonne représentation de toutes les spécificités architecturales.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_selection_donnees_04_selection_map_sia.png}
    \caption{Échantillon sélectionné de 539 tuiles par catégorie \gls{sia}}
    \label{fig:ch3_selection_donnees_04_selection_map_sia}
\end{figure}

\subsubsection{Labellisation}
La labellisation (ou annotation) des données consiste à délimiter et classifier les zones d'intérêt sur chaque image. Ce processus permet à l'algorithme d'apprentissage supervisé d'identifier les caractéristiques visuelles spécifiques de chaque classe, lui permettant ensuite de reconnaître et segmenter ces mêmes éléments sur de nouvelles images.

Dans le cadre de cette étude, une seule classe sera définie pour identifier les espaces libres sur les toitures.

\paragraph{Outils d'annotation}
La labellisation exige des outils spécialisés pour optimiser le processus, particulièrement pour la segmentation sémantique. Ce type d'annotation nécessite la création de polygones délimitant précisément les zones d'intérêt, ce qui implique souvent des formes géométriques complexes et irrégulières. L'intégration d'algorithmes de segmentation d'instance tels que SAM constitue une aide précieuse pour automatiser la sélection et la délimitation des zones à annoter.

Le choix d'un outil approprié représente un défi important, gagner du temps dans chaque annotation devient critique quand il y a 539 images à annoter. Plusieurs solutions ont été évaluées :
\begin{itemize}
    \item Label Studio \cite{label_studio_open_nodate}
    \item Roboflow \cite{roboflow_roboflow_nodate}
    \item Supervisely \cite{supervisely_supervisely_nodate}
\end{itemize}

Label Studio \cite{label_studio_open_nodate}, disponible depuis 2019, offre la possibilité d'intégrer des algorithmes de machine learning pour assister le processus d'annotation. Il s'agit d'une librairie Python permettant de gérer les annotations dans une base de données locale via une interface web. Cet outil n'a pas été retenu car l'utilisation d'aides à l'annotation tels que SAM \cite{label_studio_label_nodate} est complexe à configurer dans la version gratuite, cette fonctionnalité étant principalement accessible via leur offre commerciale.

Le deuxième outil évalué est Roboflow \cite{roboflow_roboflow_nodate}, une plateforme web qui propose gratuitement l'annotation assistée par SAM. L'un de ses principaux avantages est la possibilité d'entraîner un modèle de machine learning sur les premières images annotées, pour ensuite annoter automatiquement le reste du dataset. La version gratuite inclut l'accès à la plupart des fonctionnalités et offre quelques crédits pour l'annotation automatique.

Cet outil a été utilisé pour créer un dataset de 45 images dans le cadre d'une des pistes explorées (sous-section \ref{subsubsec:fine_tuning_sam}). L'interface utilisateur est assez intuitive et ergonomique.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures//ch3/ch3_labellisation_01_outils_01_robolfow.png}
    \caption{Interface Roboflow}
    \label{fig:ch3_labellisation_01_outils_01_robolfow}
\end{figure}

Malgré que Roboflow a tous les outils nécessaires pour effectuer des annotations rapides, SAM (Figure \ref{fig:ch3_labellisation_01_outils_02_robolfow_sam}) présente certaines limitations et ne permet qu'une sélection simplifiée des zones à annoter. Dans le contexte spécifique des toitures, cette approche nécessite de nombreux clics pour obtenir une annotation correspondant précisément à la zone souhaitée. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_labellisation_01_outils_02_robolfow_sam.png}
    \caption{Exemple d'annotation avec SAM dans Roboflow}
    \label{fig:ch3_labellisation_01_outils_02_robolfow_sam}
\end{figure}

Si l'objectif porte sur une zone clairement délimitée, SAM est suffisant. En revanche, dans des situations complexes présentant des zones d'ombrage ou des variations de contraste importantes, le processus d'annotation devient considérablement plus laborieux et chronophage.

Le troisième outil évalué, Supervisely, propose d'intégrer, en complément de SAM2, l'algorithme ClickSEG \cite{chen_conditional_2021} \cite{chen_focalclick_2022} (Figure \ref{fig:ch3_labellisation_01_outils_03_supervisely_modeles}). Supervisely offre la possibilité d'encadrer la zone d'intérêt (Figure \ref{fig:ch3_labellisation_01_outils_04_supervisely_segmentation}) pour ensuite la segmenter automatiquement. Cette approche permet de sélectionner une toiture dans son ensemble puis de retirer les parties occupées.

En pratique, les propositions de segmentation générées par ClickSEG se sont révélées significativement plus précises et pertinentes que celles produites par SAM2.

Supervisely a été retenu comme outil de labellisation car il permet d'annoter les images avec plus de précision et rapidité que avec Roboflow. Cependant, après avoir annoté quelques images, certaines limitations sont apparues, chaque annotation génère des requêtes à leurs serveurs, et le nombre de requêtes autorisé dans la version gratuite limite l'annotation à quelques images par heure.

La version payante ne présente pas cette restriction et a été jugée pertinente à cause du gain de temps considérable qu'elle apporte. Le processus complet de labellisation s'est étalé sur environ un mois et demi, représentant environ 30 heures par semaine.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.97\linewidth]{02-main/figures/ch3/ch3_labellisation_01_outils_03_supervisely_modeles.png}
    \caption{Modèles de segmentation disponibles dans Supervisely}
    \label{fig:ch3_labellisation_01_outils_03_supervisely_modeles}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.97\linewidth]{02-main/figures/ch3/ch3_labellisation_01_outils_04_supervisely_segmentation.png}
    \caption{Labellisation avec segmentation dans Supervisely}
    \label{fig:ch3_labellisation_01_outils_04_supervisely_segmentation}
\end{figure}

\paragraph{Critères d'annotation}
L'annotation d'images exige de fixer certains critères pour garantir la qualité. Les éléments suivants sont considérés comme des obstacles sur les toitures:
\begin{itemize}
    \item Balcons et terrasses praticables
    \item Toitures végétalisées
    \item Fenêtres (Velux), verrières et puits de lumière
    \item Lucarnes
    \item Cheminées, turbinettes, monoblocs, gaines
    \item Antennes (TV, satellite, téléphonie, ...)
    \item Acrotères
    \item Panneaux solaires (photovoltaïque et thermique)
    \item Constructions métalliques (support de publicité)
\end{itemize}

Le premier exemple est une toiture plate (Figure \ref{fig:labellisation_acrotere_exemple}). Les éléments considérés comme obstacles sont les gaines de ventilation, les acrotères ainsi que la structure métallique. Le reste est labellisé comme toiture libre (couleur violette sur la Figure \ref{fig:ch3_labellisation_02_exemples_01_acrotere2}). Cette zone correspond à l'espace effectivement disponible sur la toiture, une fois tous les obstacles identifiés et délimités.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_labellisation_02_exemples_01_acrotere1.png}
        \caption{Original}
        \label{fig:ch3_labellisation_02_exemples_01_acrotere1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.485\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_labellisation_02_exemples_01_acrotere2.png}
        \caption{Labellisation}
        \label{fig:ch3_labellisation_02_exemples_01_acrotere2}
    \end{subfigure}
    \caption{Exemple de labellisation 1}
    \label{fig:labellisation_acrotere_exemple}
\end{figure}

Le deuxième exemple (Figure \ref{fig:labellisation_lucarne_exemple}) représente une toiture comportant des lucarnes. La zone considérée comme libre est représentée en vert sur la Figure \ref{fig:ch3_labellisation_02_exemples_02_lucarne2}. Cette délimitation exclut les lucarnes, la zone périphérique proche du bord de toiture, les équipements techniques (antennes, éléments de ventilation) ainsi que la partie arrondie visible côté nord de la toiture.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_labellisation_02_exemples_02_lucarne1.png}
        \caption{Original}
        \label{fig:ch3_labellisation_02_exemples_02_lucarne1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_labellisation_02_exemples_02_lucarne2.png}
        \caption{Labellisation}
        \label{fig:ch3_labellisation_02_exemples_02_lucarne2}
    \end{subfigure}
    \caption{Exemple de labellisation 2}
    \label{fig:labellisation_lucarne_exemple}
\end{figure}

L'exemple suivant (Figure \ref{fig:labellisation_solaire_exemple}) représente une toiture avec des panneaux solaires existants. Les panneaux solaires, les espaces entre panneaux et les puits de lumière sont considérés comme des obstacles. Cependant, s'il y a de grands espaces entre les puits de lumière et les panneaux, ceux-ci sont considérés comme libres (couleur violette dans la Figure \ref{fig:ch3_labellisation_02_exemples_03_solaire2}).

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_labellisation_02_exemples_03_solaire1.png}
        \caption{Original}
        \label{fig:ch3_labellisation_02_exemples_03_solaire1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_labellisation_02_exemples_03_solaire2.png}
        \caption{Labellisation}
        \label{fig:ch3_labellisation_02_exemples_03_solaire2}
    \end{subfigure}
    \caption{Exemple de labellisation 3}
    \label{fig:labellisation_solaire_exemple}
\end{figure}

Le dataset inclut aussi des images qui contiennent une toiture selon la couche \acrshort{sitg} des toitures mais où il n'y a pas de surface libre. Dans la Figure \ref{fig:ch3_labellisation_02_exemples_04_image_non_annotee}, il y a bien un bâtiment dans la zone nord-est de l'image, mais celui-ci semble être une serre vitrée.

L'ajout de ce type d'exemples sans toiture exploitable devrait permettre à l'algorithme de mieux comprendre les caractéristiques recherchées dans un espace libre. Cette approche pourrait également éviter que l'algorithme considère automatiquement toutes les surfaces comme libres, ce qui l'aiderait à développer une capacité de discrimination plus fine entre les espaces réellement disponibles et ceux qui ne le sont pas.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_labellisation_02_exemples_04_image_non_annotee.png}
    \caption{Exemple d'image sans aucune surface libre disponible}
    \label{fig:ch3_labellisation_02_exemples_04_image_non_annotee}
\end{figure}

\paragraph{Résultat}
Le dataset obtenu consiste en 539 images accompagnées de leur masque d'annotation binaire. Le masque correspond à une image de la même taille que l'image originale, où chaque pixel prend une valeur de 1 si la toiture est libre à cet endroit, ou une valeur de 0 si cette zone correspond à un obstacle ou une surface non exploitable. Cette représentation binaire permet à l'algorithme d'apprentissage de distinguer clairement les espaces disponibles des zones occupées.

Pour des raisons de taille d'image, les images utilisées lors de l'annotation dans Supervisely sont des PNG comprimés (environ 2 Mo chacune). Une fois l'annotation finalisée, ces images sont remplacées par les fichiers originaux en format GeoTIFF (environ 5 Mo chacun) afin de préserver toutes les informations géographiques nécessaires ainsi que la qualité originale des images. Le dataset complet occupe ainsi un espace d'environ 4,4 Go en incluant tous les fichiers auxiliaires.

Supervisely propose également d'autres formats d'annotation que les masques binaires. L'outil offre notamment les formats YOLOv8, COCO, PASCAL VOC ainsi que leur propre format propriétaire.

\subsubsection{Post-traitement des données annotées}
Les données annotées doivent être traitées puis réparties en datasets d'entraînement, de validation et de test. Cette étape constitue une phase cruciale qui détermine la qualité de l'apprentissage du modèle et sa capacité de généralisation. La Figure \ref{fig:ch3_postprocessing_dataset_03_overview} décrit les principales phases.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_postprocessing_dataset_03_overview.png}
    \caption{Principales étapes du post-traitement}
    \label{fig:ch3_postprocessing_dataset_03_overview}
\end{figure}

\paragraph{Rognage des images}
Les données ont été annotées sur l'intégralité de l'image pour des raisons pratiques (Figure \ref{fig:ch3_postprocessing_dataset_01_exemple_dataset}), mais il semble pertinent de retirer les zones situées en dehors des toitures (Figure \ref{fig:ch3_postprocessing_dataset_02_exemple_postraitement}). Cette approche permettra au modèle de se centrer spécifiquement sur les toitures, plutôt que d'apprendre à distinguer des éléments comme des voitures ou d'autres objets présents dans l'environnement urbain.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_postprocessing_dataset_01_exemple_dataset.png}
        \caption{Tuile d'exemple}
        \label{fig:ch3_postprocessing_dataset_01_exemple_dataset}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_postprocessing_dataset_02_exemple_postraitement.png}
        \caption{Tuile d'exemple après post-traitement}
        \label{fig:ch3_postprocessing_dataset_02_exemple_postraitement}
    \end{subfigure}
    \caption{Exemple de post-traitement}
    \label{fig:exemple_post_traitement_dataset}
\end{figure}

Les images étant au format GeoTIFF, il suffit de définir à 0 (noir) toutes les zones qui n'intersectent pas avec la couche des toitures. Lors de l'annotation, il n'est pas toujours évident de distinguer une toiture d'un couvert, ce qui peut conduire à identifier des zones libres en dehors de la couche des toitures. L'opération de rognage est donc également appliquée aux annotations correspondantes, évitant ainsi que le modèle considère à tort qu'une zone masquée (pixels à 0) puisse correspondre à une toiture libre.

\paragraph{Fuite de données entre datasets}
Les tuiles présentent un recouvrement de 256 pixels qui peut causer des problèmes s'il n'est pas géré correctement. La Figure \ref{fig:ch3_postprocessing_dataset_04_data_leakage} illustre cette problématique avec 3 datasets destinés à l'entraînement d'un modèle. Si les tuiles sont assignées de manière aléatoire aux différents datasets, il existe un risque que le dataset d'entraînement contienne une partie de toiture également présente dans le dataset de test. Cette situation compromet l'évaluation des performances du modèle, puisque celui-ci aura déjà été exposé à certaines zones lors de la phase d'apprentissage, faussant ainsi les résultats obtenus sur des données supposées inconnues.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_postprocessing_dataset_04_data_leakage.png}
    \caption{Fuite de données entre datasets}
    \label{fig:ch3_postprocessing_dataset_04_data_leakage}
\end{figure}

Cette fuite de données entre datasets peut également se produire entre le dataset d'entraînement et celui de validation, ce qui conduirait le modèle à apprendre par cœur l'emplacement des toitures libres au lieu de comprendre les caractéristiques visuelles nécessaires pour identifier une toiture libre. Le modèle développerait alors une capacité de mémorisation plutôt qu'une réelle capacité de généralisation, compromettant ses performances sur de nouvelles données.

\paragraph{Traitement des chevauchements entre tuiles}
Une des manières de résoudre le problème des fuites de données consiste en un masquage sélectif d'une des tuiles en cas de recouvrement. La Figure \ref{fig:ch3_postprocessing_dataset_05_traitement_chevauchement} illustre ce processus en trois phases distinctes.

\begin{figure}[H]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.15\textwidth]{02-main//figures/ch3/ch3_postprocessing_dataset_05_traitement_chevauchement.png}}
    \caption{Traitement des chevauchements entre tuiles}
    \label{fig:ch3_postprocessing_dataset_05_traitement_chevauchement}
\end{figure}

La première étape consiste à identifier les paires de tuiles qui se chevauchent géographiquement. La deuxième phase calcule leur position relative pour déterminer précisément les zones de recouvrement. Enfin, la troisième étape procède au masquage d'une partie spécifique dans l'une des tuiles concernées, éliminant ainsi la redondance d'information entre les datasets.

La première étape est réalisée par la fonction \texttt{find\_overlapping\_tiles} (Code \ref{code:post_traitement_detection_tuile_chevauchement}) qui permet d'identifier les paires de tuiles se chevauchent.

\vspace{0.35cm}
\begin{pythoncode}
def find_overlapping_tiles(gdf, min_overlap_area=1.0):
    """
    Simple function to find overlapping tiles using spatial index.
    Returns a list of overlapping tile pairs.
    """
    overlaps = []
    n = len(gdf)
    
    # Create spatial index for fast lookups
    sindex = gdf.sindex
    
    # Check each tile against potential neighbors
    for i in range(n):
        geom1 = gdf.iloc[i]['geometry']
        tile_id1 = gdf.iloc[i]['tile_id']
        
        # Find potential overlapping tiles using bounding box
        bbox = geom1.bounds  # Get bounding box coordinates
        potential_matches = list(sindex.intersection(bbox))
        
        # Remove self-match and only check tiles with higher index
        potential_matches = [j for j in potential_matches if j > i]
        
        # Check each potential match
        for j in potential_matches:
            geom2 = gdf.iloc[j]['geometry']
            tile_id2 = gdf.iloc[j]['tile_id']
            
            # Check if geometries actually intersect
            if geom1.intersects(geom2):
                
                # Calculate overlap area
                intersection = geom1.intersection(geom2)
                overlap_area = intersection.area
                
                # Only keep overlaps above minimum threshold
                if overlap_area > min_overlap_area:
                    
                    # Calculate overlap percentages
                    overlap_pct1 = (overlap_area / geom1.area) * 100
                    overlap_pct2 = (overlap_area / geom2.area) * 100
                    
                    # Store overlap information
                    overlaps.append({
                        'tile_id1': tile_id1,
                        'tile_id2': tile_id2,
                        'overlap_area': overlap_area,
                        'overlap_percentage_1': overlap_pct1,
                        'overlap_percentage_2': overlap_pct2
                    })
    
    return overlaps
\end{pythoncode}
\captionof{code}{Détection des tuiles qui se chevauchent}
\label{code:post_traitement_detection_tuile_chevauchement}

La fonction commence par créer un index spatial pour optimiser les performances de recherche. Elle divise l'espace géographique en zones hiérarchiques (rectangles englobants) et référence les géométries présentes dans chaque zone. Cette structure permet d'éviter de comparer chaque géométrie avec l'ensemble des autres lors d'opérations spatiales, réduisant considérablement le nombre de calculs nécessaires et améliorant ainsi les performances de l'algorithme.

Pour chaque tuile, la fonction identifie ensuite les candidates potentielles en utilisant les boîtes englobantes, puis vérifie si une intersection géométrique réelle existe entre elles. Lorsqu'un recouvrement est détecté et dépasse le seuil minimal défini, elle calcule la surface d'intersection ainsi que les pourcentages de recouvrement pour chacune des deux tuiles concernées. Ces informations sont finalement stockées dans un dictionnaire Python.

La deuxième étape est réalisée par la fonction \texttt{determine\_relative\_position} (Code \ref{code:post_traitement_position_relative_tuiles}) qui traite les paires de tuiles identifiées lors de l'étape précédente. Cette fonction calcule les centroïdes des deux tuiles concernées et détermine leur position relative l'une par rapport à l'autre. Cette information de positionnement sera ensuite utilisée pour décider quelle zone masquer lors du traitement des recouvrements.

\vspace{0.35cm}
\begin{pythoncode}
def determine_relative_position(geom1, geom2):
    """
    Determine where geom1 is located relative to geom2.
    Returns: 'top', 'bottom', 'left', 'right', 'top-left', etc.
    """
    
    # Get the center points of both geometries
    center_x1, center_y1 = geom1.centroid.x, geom1.centroid.y
    center_x2, center_y2 = geom2.centroid.x, geom2.centroid.y
    
    # Compare vertical positions
    if center_y1 > center_y2:
        vertical = "top"
    elif center_y1 < center_y2:
        vertical = "bottom"
    else:
        vertical = None
    
    # Compare horizontal positions
    if center_x1 > center_x2:
        horizontal = "right"
    elif center_x1 < center_x2:
        horizontal = "left"
    else:
        horizontal = None
    
    # Combine results
    if vertical and horizontal:
        return f"{vertical}-{horizontal}"
    elif vertical:
        return vertical
    elif horizontal:
        return horizontal
    else:
        return "center"

\end{pythoncode}
\captionof{code}{Position relative des tuiles}
\label{code:post_traitement_position_relative_tuiles}

Finalement, la fonction \texttt{remove\_overlaps} (Code \ref{code:post_traitement_masquage_selectif}) applique un masquage sélectif aux tuiles qui se chevauchent, en ciblant spécifiquement celles situées à droite ou en haut selon leur position relative déterminée à l'étape précédente. Cette approche systématique garantit l'élimination des redondances tout en conservant l'intégrité des données dans chaque dataset.

\vspace{0.35cm}
\begin{pythoncode}
def remove_overlaps(overlap_df, gdf_dataset, remove_positions=['right', 'top']):
    """
    Remove overlaps by setting overlapping pixels to 0.
    
    Args:
        overlap_df: DataFrame with overlap information
        gdf_dataset: GeoDataFrame with file paths and geometries
        remove_positions: List of positions to remove (e.g., ['right', 'top'])
                         Default removes right and top tiles
    """
    
    for idx, row in overlap_df.iterrows():
        
        # Get the two overlapping files and geometries
        file1 = gdf_dataset.iloc[row['index1']]['processed_img_path_tif']
        file2 = gdf_dataset.iloc[row['index2']]['processed_img_path_tif'] 
        geom1 = gdf_dataset.iloc[row['index1']]['geometry']
        geom2 = gdf_dataset.iloc[row['index2']]['geometry']
        
        # Decide which file to modify based on position and preferences
        position = row['relative_position']
        
        # Check if any component of the position should be removed
        should_remove_geom1 = any(pos in position for pos in remove_positions)
        
        if should_remove_geom1:
            file_to_modify = file1    # Remove from geom1 (the positioned tile)
            modify_geom = geom1
        else:
            file_to_modify = file2    # Remove from geom2 (the reference tile)
            modify_geom = geom2
            
        intersection = geom1.intersection(geom2)
        
        # Open GeoTIFF and set overlapping pixels to 0
        with rasterio.open(file_to_modify, 'r+') as src:
            
            # Convert geographic intersection to pixel coordinates
            minx, miny, maxx, maxy = intersection.bounds
            window = from_bounds(minx, miny, maxx, maxy, src.transform)
            
            # Get pixel indices
            col_start = int(window.col_off)
            row_start = int(window.row_off) 
            col_end = col_start + int(window.width)
            row_end = row_start + int(window.height)
            
            # Set pixels to 0 for all bands
            for band in range(1, src.count + 1):
                data = src.read(band)
                data[row_start:row_end, col_start:col_end] = 0
                src.write(data, band)
\end{pythoncode}
\captionof{code}{Masquage sélectif}
\label{code:post_traitement_masquage_selectif}

\paragraph{Distribution stratifiées pour validation croisée}
La segmentation sémantique nécessite de grandes quantités de données annotées. Pour exploiter au mieux celles qui sont disponibles, il convient d'aller au-delà de la répartition classique entre entraînement, validation et test. L'approche traditionnelle implique que seul le dataset d'entraînement est utilisé pour former le modèle, le dataset de validation servant à évaluer les performances pendant l'entraînement, tandis que le dataset de test n'est jamais exploité durant cette phase et reste réservé à l'évaluation finale une fois l'entraînement terminé.

Une alternative plus complexe à mettre en place consiste à utiliser une validation croisée (Figure \ref{fig:ch3_postprocessing_dataset_06_kfold}). Cette méthode permet de diviser les données annotées en une partie d'entraînement constituée de 5 ensembles de données (``folds'') et un dataset de test distinct. L'avantage de cette approche réside dans le fait que chaque fold sert alternativement de dataset de validation. Ainsi, lors du premier entraînement, les folds 0, 1, 2 et 3 constituent l'ensemble d'entraînement tandis que le fold 4 sert de validation. Lors de l'entraînement suivant, les folds 0, 1, 2 et 4 sont utilisés pour l'entraînement et le fold 3 devient le dataset de validation. Cette rotation se poursuit jusqu'à ce que chaque fold ait servi de validation. Le dataset de test demeure quant à lui exclusivement réservé à l'évaluation finale, une fois l'ensemble du processus d'entraînement terminé.

\begin{figure}[H]
    \centering
    \makebox[\textwidth][c]{\includegraphics[width=1.15\textwidth]{02-main//figures/ch3/ch3_postprocessing_dataset_06_kfold.png}}
    \caption{Répartition datasets}
    \label{fig:ch3_postprocessing_dataset_06_kfold}
\end{figure}

Pour répartir les données annotées, il est nécessaire d'effectuer une stratification similaire à celle utilisée lors de la phase de sélection des données à annoter. Cette stratification analyse les combinaisons de classes \gls{sia} et d'intervalles de surface présentes dans le dataset. Les combinaisons les plus rares sont distribuées en priorité dans les différents ensembles, puis les combinaisons plus fréquentes sont réparties selon le même principe. L'objectif est de garantir que tous les datasets conservent une représentation équilibrée et représentative du dataset original annoté.

La fonction \texttt{create\_stratified\_dataset\_splits} (Code \ref{code:post_traitement_stratification}) permet de réaliser cette stratification.

\newpage
\begin{pythoncode}
def create_stratified_dataset_splits(df, test_size=0.2, n_folds=5, max_attempts=100):
    """Generate stratified dataset splits using dominant class and area bin."""
    from sklearn.preprocessing import LabelEncoder
    from iterstrat.ml_stratifiers import IterativeStratification
    
    best_result, best_score = None, float('inf')
    
    for attempt in range(max_attempts):
        # Encode categorical variables for stratification
        encoded_classes = LabelEncoder().fit_transform(df['dominant_class'])
        encoded_areas = LabelEncoder().fit_transform(df['area_bin'])
        stratification_labels = np.column_stack([encoded_classes, encoded_areas])
        # Create train/test split
        test_splitter = IterativeStratification(n_splits=int(1/test_size), order=2)
        train_indices, test_indices = list(test_splitter.split(df.values, stratification_labels))[0]
        # Initialize dataset assignments
        df_result = df.copy()
        df_result['dataset'] = n_folds  # Test set assignment
        # Create cross-validation splits from training data
        cv_splitter = IterativeStratification(n_splits=n_folds, order=2)
        cv_splits = list(cv_splitter.split(
            df_result.iloc[train_indices].values, 
            stratification_labels[train_indices]))
        # Assign CV fold numbers
        for fold_id, (_, validation_indices) in enumerate(cv_splits):
            original_indices = train_indices[validation_indices]
            df_result.loc[original_indices, 'dataset'] = fold_id
        # Calculate stratification quality metrics
        class_cv_scores = []
        for class_name in df_result['dominant_class'].unique():
            class_subset = df_result[df_result['dominant_class'] == class_name]
            fold_counts = class_subset['dataset'].value_counts()
            fold_percentages = fold_counts / len(class_subset)
            cv_score = fold_percentages.std() / fold_percentages.mean()
            class_cv_scores.append(cv_score)
        area_cv_scores = []
        for area_name in df_result['area_bin'].unique():
            area_subset = df_result[df_result['area_bin'] == area_name]
            fold_counts = area_subset['dataset'].value_counts()
            fold_percentages = fold_counts / len(area_subset)
            cv_score = fold_percentages.std() / fold_percentages.mean()
            area_cv_scores.append(cv_score)
        # Combined quality score (lower is better)
        combined_score = np.mean(class_cv_scores) + np.mean(area_cv_scores)
        # Update best result if current attempt is better
        if combined_score < best_score:
            best_score = combined_score
            best_result = df_result.copy()
    return best_result
\end{pythoncode}
\captionof{code}{Stratification pour la répartition des données annotées}
\label{code:post_traitement_stratification}

Cette fonction utilise une approche itérative pour optimiser la qualité de la stratification multicritères. L'algorithme \texttt{IterativeStratification} a l'avantage de pouvoir traiter simultanément plusieurs variables de stratification, contrairement aux méthodes classiques limitées à une seule variable catégorielle.

L'algorithme procède par allocation séquentielle des échantillons aux différents folds. À chaque itération, il sélectionne l'échantillon dont l'affectation permettra de minimiser le déséquilibre global entre les folds pour l'ensemble des variables de stratification. Cette approche garantit une distribution homogène des combinaisons de caractéristiques, même lorsque certaines combinaisons sont rares dans le dataset.

La fonction évalue la qualité de chaque tentative de stratification en calculant un score composite basé sur le coefficient de variation (CV) des distributions. Pour chaque classe dominante et chaque intervalle de surface, le coefficient de variation est défini comme :

\vspace{0.35cm}
\begin{equation}
    CV = \frac{\sigma(\text{pourcentages par fold})}{\mu(\text{pourcentages par fold})}
\end{equation}
\vspace{0.05cm}

où $\sigma$ représente l'écart-type et $\mu$ la moyenne des pourcentages de répartition entre les folds.

Un coefficient proche de zéro indique une distribution parfaitement équilibrée, tandis qu'une valeur élevée révèle des déséquilibres importants. Le score de qualité global combine les coefficients de variation moyens pour les classes dominantes et les intervalles de surface, permettant d'identifier objectivement la répartition optimale parmi les multiples tentatives générées.

Le meilleur résultat (Code \ref{code:post_traitement_stratification_resultats}) est obtenu à l'itération 84, malgré des essais avec plus de 10000 itérations.

\vspace{0.35cm}
\begin{textcode}
Target: Class CV ≤ 0.050, Area CV ≤ 0.050
  Attempt 1: Class CV: 0.106, Area CV: 0.147
  Attempt 2: Class CV: 0.099, Area CV: 0.140
  Attempt 4: Class CV: 0.102, Area CV: 0.136
  Attempt 6: Class CV: 0.113, Area CV: 0.116
  Attempt 7: Class CV: 0.117, Area CV: 0.106
  Attempt 10: Class CV: 0.109, Area CV: 0.107
  Attempt 20: Class CV: 0.124, Area CV: 0.112
  Attempt 26: Class CV: 0.111, Area CV: 0.098
  Attempt 40: Class CV: 0.127, Area CV: 0.139
  Attempt 45: Class CV: 0.122, Area CV: 0.072
  Attempt 60: Class CV: 0.119, Area CV: 0.121
  Attempt 65: Class CV: 0.090, Area CV: 0.092
  Attempt 80: Class CV: 0.121, Area CV: 0.120
  Attempt 84: Class CV: 0.086, Area CV: 0.088
  Attempt 100: Class CV: 0.136, Area CV: 0.114
Best result: Class CV: 0.086, Area CV: 0.088
Final distribution:
dataset
0    88
1    89
2    89
3    88
4    87
5    89
\end{textcode}
\captionof{code}{Résultats fonction \texttt{create\_stratified\_dataset\_splits}}
\label{code:post_traitement_stratification_resultats}

\paragraph{Validation de la distribution des datasets}











\newpage
\todo[inline]{Exemple de todo}
\section{Développement du modèle}
\subsection{Architecture du modèle} % unet et compagnie, yolo?
\subsection{Préparation des données} % dataload
\subsection{Configuration d'entraînement} % hyperparamètres
\subsection{Métriques d'évaluation} % discussion iou, precision, recall
\subsection{Processus d'entraînement} % data augmentation, stratégies de lr, patience,nb epoch
\subsection{Résultats préliminaires}

% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------
\newpage
\section{Autres pistes explorées}
\label{sec:pistes_explorees}
Plusieurs autres approches ont été explorées, le but initial étant d'éviter de devoir créer un dataset. La génération d'un dataset pour une tâche tel que la segmentation sémantique est assez chronophage et laborieux. La première approche est d'essayer de classifier les données géomatiques, la deuxième approche implique l'utilisation de segment-anything-model.

\subsection{Classification}
La classification des toitures est une approche naïve pour déterminer quelles toitures sont disponibles en utilisant les couches des toitures et superstructures de \acrshort{sitg}.

\subsubsection{Méthodologie}
La Figure \ref{fig:ch3_piste_exploree_classification_01_workflow} résume les principales étapes. 

\begin{figure}[H]
    \centering
    \makebox[\textwidth]{\includegraphics[width=1.3\linewidth]{02-main//figures/ch3/ch3_piste_exploree_classification_01_workflow.png}}
    \caption{Schéma classification des toitures}
    \label{fig:ch3_piste_exploree_classification_01_workflow}
\end{figure}

L'objectif est de créer 3 classes en utilisant la couche des toitures et celle des superstructures:
\begin{itemize}
    \item Classe 1: Toiture totalement occupée
    \item Classe 2: Toiture partiellement occupée
    \item Classe 3: Toiture libre
\end{itemize}
Premièrement, les toitures de moins de 2 \si{\unit{\square\meter}} sont éliminées car jugées trop petites.

L'étape suivante (Figure \ref{fig:piste_exploree_classification_image_exemple}) est de déterminer si la toiture est un polygone complètement fermé ou s'il y a un autre polygone à l'intérieur. La Figure \ref{fig:ch3_piste_exploree_classification_02_image_originale} représente une image d'exemple pour illustrer cette étape, la toiture est un toit à deux pans inclinés avec des lucarnes. La Figure \ref{fig:ch3_piste_exploree_classification_03_couche_toiture} superpose la couche des toitures sur la Figure \ref{fig:ch3_piste_exploree_classification_02_image_originale}, on observe que la couche des toitures a bien un polygone assigné à chacune des lucarnes. La Figure \ref{fig:ch3_piste_exploree_classification_04_image_resultante} représente le résultat pour la partie nord de la toiture, la partie intérieur (lucarne) a été éliminée et tout ce qui est hors polygone a été enlevé.

A continuation, il faut vérifier la présence d'une superstructure (couche superstructure) sur la toiture. Dans le cas de la Figure \ref{fig:piste_exploree_classification_image_exemple}, il n'y a pas de superstructure dans la toiture.

Les deux étapes précédentes vont déterminer l'action à réaliser sur l'image, ainsi que sa classification. Si l'on reprend le schéma de la Figure \ref{fig:ch3_piste_exploree_classification_01_workflow} pour l'exemple étape par étape:
\begin{enumerate}
    \item Surface > 2 \si{\unit{\square\meter}} : Oui
    \item Polygone totalement inclus à l'intérieur de celui de la toiture : Oui
    \item Superstructure sur la toiture : Non
    \item Classe 3b: Supprimer "trou" de l'image
    \item Toiture finalement classée comme "libre"
\end{enumerate}

\begin{figure}[H]
    \centering
    
    % Première ligne
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_piste_exploree_classification_02_image_originale.png}
        \caption{Image d'exemple}
        \label{fig:ch3_piste_exploree_classification_02_image_originale}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_piste_exploree_classification_03_couche_toiture.png}
        \caption{Couche toiture superposée}
        \label{fig:ch3_piste_exploree_classification_03_couche_toiture}
    \end{subfigure}
    
    \vspace{0.35cm} % Espace entre les lignes
    
    % Deuxième ligne
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_piste_exploree_classification_04_image_resultante.png}
        \caption{Résultat final}
        \label{fig:ch3_piste_exploree_classification_04_image_resultante}
    \end{subfigure}

    \caption{Exemple de toiture avec un "trou" et sans superstructure}
    \label{fig:piste_exploree_classification_image_exemple}
\end{figure}

\subsubsection{Résultats}

La Figure \ref{fig:ch3_piste_exploree_classification_05_classification_simplified} représente la classification intermédiaire selon la présence d'un polygone à l'intérieur de la toiture et de la présence de superstructure (voir Figure \ref{fig:ch3_piste_exploree_classification_01_workflow}). La grande majorité des toitures sont classées comme "3a", c'est à dire des toitures qui n'ont pas de superstructure ni d'autre polygone à l'intérieur. Ce sont des toitures à priori libres.

La Figure \ref{fig:ch3_piste_exploree_classification_06_classification_finale} montre la classification finale en 3 classes. Les résultats indiquent que quasiment toutes les toitures sont libres, ce qui est loin d'être le cas. Le problème est la couche des superstructures, celle-ci n'est pas complète et pas tous les éléments en dessous de 9 \si{\unit{\square\meter}} sont représentés. La classification ne tient pas en compte de la réalité terrain et sa précision et pertinence va dépendre de la qualité des données géomatiques utilisées.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures/ch3/ch3_piste_exploree_classification_05_classification_intermediaire.png}
    \caption{Classification intermédiaire}
    \label{fig:ch3_piste_exploree_classification_05_classification_simplified}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main//figures/ch3/ch3_piste_exploree_classification_06_classification_finale.png}
    \caption{Classification finale}
    \label{fig:ch3_piste_exploree_classification_06_classification_finale}
\end{figure}

La Figure \ref{fig:piste_exploree_classification_resultats_explications} représente un exemple de la problématique, les superstructures présentes sur le toit (Figure \ref{fig:ch3_piste_exploree_classification_10_resultats_image_sp}) ne sont pas toutes représentées (Figure \ref{fig:ch3_piste_exploree_classification_07_resultats_image_exemple}). La couche des toitures (Figure \ref{fig:ch3_piste_exploree_classification_08_resultats_image_toiture}) inclus aussi des balcons et terrasses, ce qui complique significativement la tâche de classification. Il n'y a pas le découpage pour cette toiture (similaire Figure \ref{fig:ch3_piste_exploree_classification_04_image_resultante}), car il y a un bug dans le script qui classifie et découpe les toitures. Finalement, il y a aussi des problèmes d’alignement entre les orthophotos et les superstructures qui rendent peu fiables les découpes nécessaires pour enlever les superstructures des toitures dans la dernière phase de la classification.

\begin{figure}[H]
    \centering
    
    % Première ligne
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_piste_exploree_classification_07_resultats_image_exemple.png}
        \caption{Image d'exemple}
        \label{fig:ch3_piste_exploree_classification_07_resultats_image_exemple}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_piste_exploree_classification_08_resultats_image_toiture.png}
        \caption{Couche des toitures}
        \label{fig:ch3_piste_exploree_classification_08_resultats_image_toiture}
    \end{subfigure}
    
    \vspace{0.35cm} % Espace entre les lignes
    
    % Deuxième ligne
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_piste_exploree_classification_10_resultats_image_sp.png}
        \caption{Couche des superstructures}
        \label{fig:ch3_piste_exploree_classification_10_resultats_image_sp}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_piste_exploree_classification_09_resultats_image__toiture_sp.png}
        \caption{Couche des toitures et superstructures}
        \label{fig:ch3_piste_exploree_classification_09_resultats_image__toiture_sp}
    \end{subfigure}

    \caption{Exemple de toiture problématique pour la classification}
    \label{fig:piste_exploree_classification_resultats_explications}
\end{figure}

Pour conclure, les différents problèmes rencontrés et le manque de fiabilité du résultat final ont fait que la piste de la classification n'a pas été retenue.


\newpage
\subsection{SAM}
Une autre piste explorée est l'utilisation de segment-anything-model (SAM). Cet algorithme a l'avantage de permettre une segmentation efficace sur des images sur lesquels SAM n'a pas spécifiquement été entraîné. \acrshort{stdl} avait déjà exploré cette piste (section \ref{subsec:stdl_analyse}) avec quelques différences entre les méthodologies utilisée.

\subsubsection{Méthodologie}
La Figure \ref{fig:essai_algo_sam} résume les différentes étapes:
\begin{enumerate}
    \item Mettre en noir tout ce qui est hors toiture (Figure \ref{fig:ch3_essai_sam_01_image_original})
    \item Détermination zone d'intêret (Figure \ref{fig:ch3_essai_sam_02_ROI})
    \item SAM va segmenter toute l'image (Figure \ref{fig:ch3_essai_sam_03_200_masks})
    \item Filtrer les masques (polygones segmentés) (Figure \ref{fig:ch3_essai_sam_04_194_filtered_masks})
    \item Visualisation des masques filtrés avec des couleurs plus vives pour vérification visuelle (Figure \ref{fig:ch3_essai_sam_05_filtered_masks_overlay})
    \item Détermination de l'espace libre (Figure \ref{fig:ch3_essai_sam_06_une_zone_libre})
\end{enumerate}

La première étape (Figure \ref{fig:ch3_essai_sam_01_image_original}) est de fusionner tous les polygones qui délimitent la toiture. Ce grand polygone de toiture va permettre de centrer l'attention de SAM sur la toiture, les zones hors toitures peuvent être considérées comme du bruit et mises en noir. Un avantage notable de cette démarche est d'éviter du temps de calcul à SAM.

La deuxième étape (Figure \ref{fig:ch3_essai_sam_02_ROI}) est de déterminer la zone d'intérêt (ROI). Cette étape utilise la librairie python pillow et permet de mettre en évidence les zones sombres à l'intérieur de la toiture.

La troisième étape (Figure \ref{fig:ch3_essai_sam_03_200_masks}) utilise l'algorithme SAM pour réaliser la segmentation complète de l'image de la Figure \ref{fig:ch3_essai_sam_01_image_original}. Dans ce cas, un total de 200 masques sont segmentés. Le temps de calcul est de 7 minutes pour une image de toiture. SAM dispose de plusieurs paramètres qui peuvent augmenter significativement le temps de calcul; SAM peut par exemple diviser l'image en plusieurs parties pour améliorer la segmentation, plus cette partition est fine, meilleurs seront les résultats. La documentation de SAM est assez rudimentaire et n'explique pas clairement toutes les options disponibles.

La quatrième étape (Figure \ref{fig:ch3_essai_sam_04_194_filtered_masks}) consiste à filtrer les polygones segmentés selon trois critères principaux :
\begin{itemize}
    \item Recouvrement avec la ROI : les masques doivent avoir un recouvrement supérieur à 50\% avec la zone d'intérêt
    \item Taille minimale : élimination des polygones de moins de 50 pixels (paramètre SAM) et suppression additionnelle des masques avec moins de 100 pixels
    \item Qualité de segmentation : utilisation des seuils SAM avec un IoU prédit > 0.85 et un score de stabilité > 0.85
\end{itemize}
Cette étape réduit le nombre de masques de 200 à 194, éliminant principalement les artefacts de segmentation hors toiture et les zones trop petites.

La cinquième étape (Figure \ref{fig:ch3_essai_sam_05_filtered_masks_overlay}) propose une visualisation colorée des masques filtrés pour faciliter la vérification visuelle des résultats de segmentation.

La sixième étape (Figure \ref{fig:ch3_essai_sam_06_une_zone_libre}) détermine l'espace libre en combinant plusieurs critères :

\begin{itemize}
    \item Critères géométriques:
    \begin{itemize}
        \item Zone tampon de 0.5 m autour des obstacles détectés
        \item Ratio de largeur/hauteur pour éliminer les masques long mais pas suffisament larges pour être intéressants pour la pose de panneaux solaires
        \item Taille du masque minimum de 10 m² par défaut (soit 4000 pixels à 5 cm/pixel)
    \end{itemize}
    \item Critère de luminosité:
        \begin{itemize}
            \item Filtre sur les zone sombres qui ont une luminosité de moins de 60\% de la moyenne globale de l'image
        \end{itemize}
\end{itemize}

\begin{figure}[H]
    \centering
    
    % Première ligne
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_essai_sam_01_image_original.png}
        \caption{Image d'exemple}
        \label{fig:ch3_essai_sam_01_image_original}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_essai_sam_02_ROI.png}
        \caption{Zone d’intérêt (ROI)}
        \label{fig:ch3_essai_sam_02_ROI}
    \end{subfigure}
    
    \vspace{0.35cm} % Espace entre les lignes
    
    % Deuxième ligne
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_essai_sam_03_200_masks.png}
        \caption{Polygones segmentés (200)}
        \label{fig:ch3_essai_sam_03_200_masks}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_essai_sam_04_194_filtered_masks.png}
        \caption{Polygone segmentés filtrés (194)}
        \label{fig:ch3_essai_sam_04_194_filtered_masks}
    \end{subfigure}

    \vspace{0.35cm} % Espace entre les lignes
    
    % Troisième ligne
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_essai_sam_05_filtered_masks_overlay.png}
        \caption{Mise en évidence des polygones filtrés}
        \label{fig:ch3_essai_sam_05_filtered_masks_overlay}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{02-main/figures/ch3/ch3_essai_sam_06_une_zone_libre.png}
        \caption{Espace libre}
        \label{fig:ch3_essai_sam_06_une_zone_libre}
    \end{subfigure}

    \caption{Essai d'utilisation de SAM}
    \label{fig:essai_algo_sam}
\end{figure}

\subsubsection{Fine-tuning de SAM}
\label{subsubsec:fine_tuning_sam}
La piste d'un fine-tuning de SAM pour mieux l'adapter à la tâche d'identification des espaces libres a été explorée. Un dataset de 45 images (Figure \ref{fig:ch3_piste_exploree_classification_11_fine_tuning_dataset}) n'a pas permis d'améliorer significativement les performances du modèle. Une des problématiques rencontrées lors de la création de ce dataset est qu'il faut identifier tous les obstacles présents sur la toiture, ce qui prend énormément de temps et nécessite une grande quantité de classes différentes.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{02-main/figures/ch3/ch3_piste_exploree_classification_11_fine_tuning_dataset.png}
    \caption{Image du dataset pour le fine-tuning SAM}
    \label{fig:ch3_piste_exploree_classification_11_fine_tuning_dataset}
\end{figure}

\subsubsection{Résultats}

SAM segmente correctement les toitures bien éclairées avec un contraste suffisant entre obstacles et surface. Les résultats se dégradent significativement en présence d'ombrages ou de faible contraste.

Les principales limitations sont:
\begin{itemize}
    \item Principal problème rencontré sont les ombrages. SAM confond les zones ombragées avec l'arrière-plan noir, même avec les filtres de luminosité implémentés. Cela génère des faux négatifs dans les zones ombragées.
    \item Le temps de calcul par image est de 7 minutes (sur \acrshort{gpu}), ce qui confirme les résultats de \acrshort{stdl}. La mise à l'échelle du canton est problématique.
    \item Les performances de segmentation sont directement corrélées à la résolution et au contraste de l'image d'entrée.
\end{itemize}

Le fine-tuning avec 45 images annotées n'améliore pas les performances. Le dataset reste trop petit pour un modèle de cette complexité, et l'annotation manuelle de tous les obstacles de toiture est très chronophage.

Pour conclure, SAM fonctionne bien sur des images de qualité avec un bon éclairage, par contre son utilité reste limitée à cause des ombrages et du temps de calcul nécessaire.

% -----------------------------------------------------------------------------
\section{Synthèse}